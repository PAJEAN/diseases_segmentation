L'expérimentation se déroule sur un jeu de données maladies/symptômes provenant de la publication "Human symptoms-disease network, Zhou et al. 2014". Ce jeu contient initialement 4217 maladies. Cependant, nous exploitons 1755 d'entre elles pour le corpus 1 et 1005 pour le corpus 2. Pour le corpus 1 deux filtres sont employés. Le premier filtre les symptômes sur le nombre de co-occurrences avec la maladie, ce nombre doit être strictement supérieur à 1. Le second filtre considère uniquement les maladies qui ont un seul ascendant dans la branche C du Mesh (C pour Diseases "https://meshb.nlm.nih.gov/treeView"), ainsi nous nous situons au sein d'un problème multi classes mais mono label. Pour le corpus 2, les mêmes filtres sont conservés mais nous avons limitons le nombre de symptômes par maladie à 50 au maximum.

L'expérimentation menée au sein de cette étude repose sur la comparaison des distances vectorielles employées dans l'article et des distances sémantiques.

# Chaîne expérimentale

* Étape 1: Formater les fichiers queries.tsv (utilisé pour la SML) et le fichier résultant de la SML (intitulé ici sml_results.tsv). Le script formatting.py avec l'option -a te permet d'extraire l'ensemble des colonnes issues du fichier de résultats. Chaque mesure va créer un fichier dans le dossier mesh/pairwise_distances (pairwise pour des "pairwise" de maladies). 
* Étape 2: Calculer les distances vectorielle (baseline) entre les vecteurs de symptômes associés aux maladies. Dans l'article, ils exploitent la valeur de tf-idf qu'ils ont extrait au sein des textes. J'ai repris cette valeur. Pour cela, tu as le script baseline_compute_pairwise_distance.py qui va te créer un fichier baseline.json dans le dossier pairwise_distances. Pour utiliser des caractéristiques binaires, l'option -b doit être renseignée.
* Étape 3: Réaliser l'étape de partitionnement agglomérative en tenant compte des distances calculées entre les maladies. Le script clustering.py avec l'option -a te permet de réaliser le clustering sur chaque fichier au sein du dossier pairwise_distances. Chaque sortie de cette étape va créer un fichier dans le dossier clusters.
* Étape 4: Évaluer les clusters au travers des mesures: pureté, f1-mesure et rank index. Pour cela tu peux utiliser le script evaluation.py avec l'option -a pour calculer les différentes évaluations sur l'ensemble des fichiers au sein du dossier clusters.
